{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f52eb2",
   "metadata": {},
   "source": [
    "<!-- \n",
    "用ipython notebook\n",
    "用numpy，包括函数调用及向量矩阵运算\n",
    "理解“广播”的概念\n",
    "向量化代码 \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd05d0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Hello World\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (≈ 1 line of code)\n",
    "test = \"Hello World\"\n",
    "### END CODE HERE ###\n",
    "print (\"test: \" + test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7a0d9",
   "metadata": {},
   "source": [
    "#学习一些关键的numpy函数，例如np.exp，np.log和np.reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c65443",
   "metadata": {},
   "source": [
    "# 1.1- sigmoid function和np.exp（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aadebf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def sigmoid(x):\n",
    "    #float x,sigmoid_x\n",
    "    sigmoid_x = 1/(1+math.exp(-x))\n",
    "    return sigmoid_x\n",
    "sigmoid(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0682eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### One reason why we use \"numpy\" instead of \"math\" in Deep Learning ###\n",
    "# x = [1, 2, 3]\n",
    "# sigmoid(x) # you will see this give an error when you run it, because x is a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c52d4",
   "metadata": {},
   "source": [
    "np.exp就不同，可以计算矢量vector,可以依次计算exp（x）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bab2a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71828183  7.3890561  20.08553692]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# example of np.exp\n",
    "x = np.array([1, 2, 3])\n",
    "print(np.exp(x)) # result is (exp(1), exp(2), exp(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b456f36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid_np(x):\n",
    "    #float x,sigmoid_x\n",
    "    sigmoid_x = 1/(1+np.exp(-x))\n",
    "    return sigmoid_x\n",
    "x = np.array([1, 2, 3])\n",
    "sigmoid_np(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34d7ac",
   "metadata": {},
   "source": [
    "# 1.2- Sigmoid gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aa59189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_derivative(x) = [0.19661193 0.10499359 0.04517666]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid_gradient(x):              #sigmoid derivative\n",
    "    #float x,sigmoid_x\n",
    "    sigmoid_x = 1/(1+np.exp(-x))\n",
    "    dsigmoid_x = sigmoid_x*(1-sigmoid_x)\n",
    "    return dsigmoid_x\n",
    "x = np.array([1, 2, 3])\n",
    "print (\"sigmoid_derivative(x) = \" + str(sigmoid_gradient(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe9779",
   "metadata": {},
   "source": [
    "# 1.3- 重塑数组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f9a2a",
   "metadata": {},
   "source": [
    "深度学习中两个常用的numpy函数是np.shape和np.reshape()。\n",
    "-X.shape用于获取矩阵/向量X的shape（维度）\n",
    "-X.reshape（...）用于将X重塑为其他尺寸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c263f",
   "metadata": {},
   "source": [
    "练习：实现image2vector() ,该输入采用维度为(length, height, 3)的输入，并返回维度为(length*height*3, 1)的向量。\n",
    "例如，如果你想将形为（a，b，c）的数组v重塑为维度为(a*b, 3)的向量，则可以执行以下操作：\n",
    "\n",
    "v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c\n",
    "-请不要将图像的尺寸硬编码为常数。而是通过image.shape [0]等来查找所需的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fe9be48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 2)\n",
      "image2vector(image) = [[0.67826139]\n",
      " [0.29380381]\n",
      " [0.90714982]\n",
      " [0.52835647]\n",
      " [0.4215251 ]\n",
      " [0.45017551]\n",
      " [0.92814219]\n",
      " [0.96677647]\n",
      " [0.85304703]\n",
      " [0.52351845]\n",
      " [0.19981397]\n",
      " [0.27417313]\n",
      " [0.60659855]\n",
      " [0.00533165]\n",
      " [0.10820313]\n",
      " [0.49978937]\n",
      " [0.34144279]\n",
      " [0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# GRADED FUNCTION: image2vector\n",
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- a numpy array of shape (length, height, depth)\n",
    "    \n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    v = image.reshape(image.shape[0] * image.shape[1] * image.shape[2], 1)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return v\n",
    "# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB values\n",
    "image = np.array([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "print(image.shape)\n",
    "print (\"image2vector(image) = \" + str(image2vector(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3eeea6",
   "metadata": {},
   "source": [
    "# 1.4- 行标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7fac42",
   "metadata": {},
   "source": [
    "由于归一化后梯度下降的收敛速度更快，通常会表现出更好的效果。 通过归一化，也就是将x更改为:将x的每个行向量除以其范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef080574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizeRows(x) = [[0.         0.6        0.8       ]\n",
      " [0.13736056 0.82416338 0.54944226]]\n"
     ]
    }
   ],
   "source": [
    "# GRADED FUNCTION: normalizeRows\n",
    "\n",
    "def normalizeRows(x):\n",
    "    \"\"\"\n",
    "    Implement a function that normalizes each row of the matrix x (to have unit length).\n",
    "    \n",
    "    Argument:\n",
    "    x -- A numpy matrix of shape (n, m)\n",
    "    \n",
    "    Returns:\n",
    "    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    # Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
    "    x_norm = np.linalg.norm(x, axis = 1, keepdims = True)\n",
    "    \n",
    "    # Divide x by its norm.\n",
    "    x = x / x_norm\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return x\n",
    "x = np.array([\n",
    "    [0, 3, 4],\n",
    "    [1, 6, 4]])\n",
    "print(\"normalizeRows(x) = \" + str(normalizeRows(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6c271",
   "metadata": {},
   "source": [
    "# 1.5- 广播和softmax函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6caeb1",
   "metadata": {},
   "source": [
    "这对于在不同形状的数组之间执行数学运算非常有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9ff96cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax(x) = [[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04\n",
      "  1.21052389e-04]\n",
      " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04\n",
      "  8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Calculates the softmax for each row of the input x.\n",
    "\n",
    "    Your code should work for a row vector and also for matrices of shape (n, m).\n",
    "\n",
    "    Argument:\n",
    "    x -- A numpy matrix of shape (n,m)\n",
    "\n",
    "    Returns:\n",
    "    s -- A numpy matrix equal to the softmax of x, of shape (n,m)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    # Apply exp() element-wise to x. Use np.exp(...).\n",
    "    s1 = np.exp(x)\n",
    "    s2 = np.sum(s1,axis=1,keepdims=True)\n",
    "    softmax_x=s1/s2\n",
    "    return softmax_x\n",
    "x = np.array([\n",
    "    [9, 2, 5, 0, 0],\n",
    "    [7, 5, 0, 0 ,0]])\n",
    "print(\"softmax(x) = \" + str(softmax(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66151cc",
   "metadata": {},
   "source": [
    "# 2.实现L1和L2损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5afe90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.1\n"
     ]
    }
   ],
   "source": [
    "# GRADED FUNCTION: L1\n",
    "\n",
    "def L1(yhat, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    yhat -- vector of size m (predicted labels)\n",
    "    y -- vector of size m (true labels)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- the value of the L1 loss function defined above\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    loss = np.sum(np.abs(y - yhat))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss\n",
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = \" + str(L1(yhat,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "950c4d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "# GRADED FUNCTION: L2\n",
    "\n",
    "def L2(yhat, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    yhat -- vector of size m (predicted labels)\n",
    "    y -- vector of size m (true labels)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- the value of the L2 loss function defined above\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    loss = np.dot((y - yhat),(y - yhat).T)\n",
    "#     loss=np.sum(np.multiply((y-yhat),(y-yhat)))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss\n",
    "yhat = np.array([.9, 0.2, 0.1, .4, .9])\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L2 = \" + str(L2(yhat,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67341c9b",
   "metadata": {},
   "source": [
    "主要是机器学习中的最基本的编程知识，参考:\n",
    "https://www.heywhale.com/mw/project/5dd236a800b0b900365eca9b\n",
    "numpy数组向量化，以及numpy数组常用的函数，\n",
    "矩阵一整行求和，\n",
    "矩阵一整行求2范数（算术平方和），\n",
    "不同型的矩阵广播机制\n",
    "sigmoid函数及其导数，\n",
    "L1范数与L2范数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
